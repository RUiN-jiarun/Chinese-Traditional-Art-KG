# 毕业设计（论文）学习记录

## 7.14

*计划从知识图谱的构建角度开始，找一些与知识图谱相关的内容，同时根据老师的指导进行数据的收集*

基本需要这几个重要步骤：

* 数据获取
  * 用scrapy框架
  * 对于词条**抽取哪些信息**需要再商量或者研究
  * 采用并行爬虫可以加速
* 数据库的建立
* 三元组的表达形式：（实体A，实体B，关系）
  * RDF检索语言，基于RDF的存储的开源方式
  * 存储数据库：关系型数据库？图数据库？文档数据库？
  * 图数据库的话，用哪种数据库？——
  * 备选项：Word2Vec对三元组的表示学习，可以建立稠密向量
* 构建工具
  * Java的Apache Jena
  * python的spacy库
* 知识融合



另外，确定了需要爬取的网页：（共143个页面）

[分类:明朝画家 - 维基百科，自由的百科全书 (wikipedia.org)](https://zh.wikipedia.org/wiki/Category:明朝畫家)



## 7.16

**学习scrapy框架**

环境与框架配置：

```sh
$ pip install wheel
$ pip install scrapy
$ scrapy startproject wiki_crawler
$ scrapy genspider main zh.wikipedia.org
```

下一步：对要爬取的页面要进行分析

```python
l.add_xpath('titles','//h3/ul/li/a/text()')
l.add_xpath('urls','//h3/ul/li/a/@href')
```

执行

```sh
$ scrapy crawl main --nolog
```

**甘霖娘！出错啦！这个xpath路径不对！！**

还是老老实实从xpath看起。。。



## 7.20

**Xpath**用于HTML或XML中系欸DNA的选择

* 多级定位：从根节点开始选择定位，以`/`开头，返回所有匹配的子节点选择器列表
* 跳级定位：不从根节点开始而是全局匹配，以`//`开头，返回所有能够匹配到的结果
* 属性匹配：使用id、class、title、href等来辅助查询，结合多级定位或跳级定位，如`//body/div[@id="header"]`
* 提取内容：在定位后加`/text()`，再调用get()或getall()方法获得
* 提取属性：如在定位后加`/@class`获得类信息



## 8.4

我是废物。。旷了好几天。。。

今天整了一点，把路径找好了

* 运行路径在`data_gathering/wiki`

* xpath：

  ```python
  print(response.xpath('//body/div[@id="content"]/div[@id="bodyContent"]/div[@id="mw-content-text"] \
                                  /div[@class="mw-category-generated"]/div[@id="mw-pages"] \
                                  /div[@class="mw-content-ltr"]/div[@class="mw-category"]/div[@class="mw-category-group"]/ul/li/a/text()'))
  ```




## 先爬
